import pandas as pd
import os
import csv

tempo = '80' # Set as the value of one the available metronome tracks in the "metronome_tracks" folder

midi_performance_note = 79

# STROKE ROLL RUDIMENT SETTINGS

# Define type of stroke roll rudiment [single, double, triple], and interval's width (percentage) [50, 75]:
strokeroll_type = 'single'
interval_width = 50

# Define number of notes per beat (for a 4/4 time signature) of the stroke roll rudiment [single = 2, double = 4, triple = 6]:
if strokeroll_type == 'single':
    notes_per_beat = 2
elif strokeroll_type == 'double':
    notes_per_beat = 4
elif strokeroll_type == 'triple':
    notes_per_beat = 6

# Calculate number of intervals (for a 4/4 time signature), based on the interval's width and number of notes per beat:
notes_per_bar = notes_per_beat * 4

if interval_width < 100:
    intervals_per_note = 2
elif interval_width == 100:
    intervals_per_note = 1

intervals_per_bar = notes_per_bar * intervals_per_note

# Calculate total number of notes and intervals for sequences (for pre-click + 16 + 8 + 16 open close open):
notes_in_sequence = notes_per_bar * 41
intervals_in_sequence = intervals_per_bar * 41

notes_in_performance = notes_per_bar * 40
intervals_in_performance = intervals_per_bar * 40

# Define ranges of count exclussion
preclick_group_end = notes_per_bar + 1
cue_group = str(intervals_in_sequence + 1)
cue_group_string = f"group {cue_group}"


# ---------------------------------------


recording_name = f'{tempo}_strokeroll_{strokeroll_type}_{interval_width}_perfect_recording'


# Specify the CSV file of the recording.
csv_file_path = f'recordings/{recording_name}.csv'

# Load the CSV file
df_raw = pd.read_csv(csv_file_path)



#--------------------------------------------

# 1 FILTERING

# Filter out 'note_off' rows
filtering_1 = df_raw[df_raw['type'] != 'note_off']
# Convert the results to a DataFrame
df_filtered_1 = pd.DataFrame(filtering_1)
# Filter out notes different to the target drum pad (remove those that are not note 79)
filtering_2 = df_filtered_1[df_filtered_1['note'] == midi_performance_note]
# Convert the results to a DataFrame
df_filtered_2 = pd.DataFrame(filtering_2)

#--------------------------------------------

# 2 ISOLATION

# Isolate "time" values
isolation = df_filtered_2['time']
# Convert the results to a DataFrame
df_isolated = pd.DataFrame(isolation)

#--------------------------------------------

#3 ALIGNMENT

# Path for the intervals' file
intervals_path = f"interval_tracks_strokeroll/{tempo}_intervals_strokeroll_{strokeroll_type}_{interval_width}.csv"
df_intervals = pd.read_csv(intervals_path)

# Sort the intervals
df_intervals = df_intervals.sort_values('start')
alignement = []
times_set = set(df_isolated['time'])

# For each interval, find the time that falls into it
for _, interval in df_intervals.iterrows():
    interval_dict = interval.to_dict()
    performance_times = [time for time in times_set if interval['start'] <= time <= interval['end']]
    if performance_times:
        for time in performance_times:
            interval_dict['performance'] = time
            alignement.append(interval_dict.copy())
    else:
        interval_dict['performance'] = 'N/A'
        alignement.append(interval_dict.copy())

# Convert the results to a DataFrame
df_aligned = pd.DataFrame(alignement)

#--------------------------------------------

# 4 GROUPING

# Function to determine interval group with continuous naming across "b" values
def determine_continuous_interval_group(interval):
    # Extract "b" value and "i" value
    b_value, i_value = map(int, interval[1:].split('i'))
    # Calculate the overall sequence number depending on the "b" and "i" values of the rudiment
    overall_sequence_num = (b_value - 1) * intervals_per_bar + i_value
    # Determine the note number based on the overall sequence
    note_num = (overall_sequence_num + 1) // 2
    return f"group {note_num}"

# Define the list of accurate intervals
if strokeroll_type == 'single':
    accurate_intervals = ['i1', 'i3', 'i5', 'i7', 'i9', 'i11', 'i13', 'i15']
elif strokeroll_type == 'double':
    accurate_intervals = ['i1', 'i3', 'i5', 'i7', 'i9', 'i11', 'i13', 'i15', 'i17', 'i19', 'i21', 'i23', 'i25', 'i27', 'i29', 'i31']
elif strokeroll_type == 'triple':
    accurate_intervals = ['i1', 'i3', 'i5', 'i7', 'i9', 'i11', 'i13', 'i15', 'i17', 'i19', 'i21', 'i23', 'i25', 'i27', 'i29', 'i31', 'i33', 'i35', 'i37', 'i39', 'i41', 'i43', 'i45', 'i47']


# Function to determine interval type
def determine_interval_type(interval):
    # Extract the numeric part after "i" from the interval identifier
    interval_num = int(interval.split('i')[-1])
    # Determine if the interval is accurate or non-accurate based on whether the number is odd (accurate) or even (non-accurate)
    return "accurate" if interval_num % 2 != 0 else "non-accurate"

# Apply the functions to create the new columns
df_aligned['interval type'] = df_aligned['interval'].apply(determine_interval_type)
df_aligned['interval group'] = df_aligned['interval'].apply(determine_continuous_interval_group)

grouping = df_aligned

# Convert the results to a DataFrame
df_grouped = pd.DataFrame(grouping)

# Save the grouped data to a CSV file
base_name = os.path.basename(csv_file_path).rsplit('.', 1)[0]
output_folder_path_recording_grouped = f"results_grouped"
os.makedirs(output_folder_path_recording_grouped, exist_ok=True)
df_grouped.to_csv(os.path.join(output_folder_path_recording_grouped, f"{base_name}_results_grouped.csv"), index=False)

#--------------------------------------------

# 5 COUNTING

accurate_count = 0
non_accurate_count = 0

accurate_groups = {}

counted_accurate_intervals = set()
counted_non_accurate_intervals = set()

for index, row in df_grouped.iterrows():
    group = row['interval group'] 
    if group in [f"group {i}" for i in range(1, preclick_group_end)] or group == cue_group_string: # Skip the pre-click groups and the last group (cue out)
        continue  

    if pd.notnull(row['performance']) and row['performance'] != "N/A": # Check if 'performance' is not "N/A" and not null
        interval_name = row['interval']

        if row['interval type'] == 'accurate':
            if interval_name not in counted_accurate_intervals:
                counted_accurate_intervals.add(interval_name)
                accurate_count += 1
                accurate_groups[group] = True  
        elif row['interval type'] == 'non-accurate':
            if interval_name not in counted_non_accurate_intervals and group not in accurate_groups:
                counted_non_accurate_intervals.add(interval_name)
                non_accurate_count += 1

total_intervals = notes_in_performance
overall_count = accurate_count

accurate_count_percentage = (accurate_count / total_intervals) * 100
non_accurate_count_percentage = (non_accurate_count / total_intervals) * 100
overall_count_percentage = ((overall_count)/ total_intervals) * 100

print(f"---------------------------------")
print(f"PERFORMANCE: {recording_name}, tempo {tempo}")
print(f"---------------------------------")
print(f"RESULTS")
print(f"Accurate intervals hit: {accurate_count} (out of {total_intervals})")
print(f"Non-Accurate intervals hit - missing accurate: {non_accurate_count} (out of {total_intervals})")
print(f"Overall count: {overall_count} (out of {total_intervals})")
print(f"---------------------------------")
print(f"SCORE: {overall_count_percentage:.2f}%")
print(f"---------------------------------")

#--------------------------------------------

data = [
    ["result", "value", "out_of", "percentage"],
    ["overall_accurate_intervals", accurate_count, total_intervals, f"{accurate_count_percentage:.2f}%"],
    ["overall_non_accurate_intervals_missing_accurate", non_accurate_count, total_intervals, f"{non_accurate_count_percentage:.2f}%"],
    ["overall count", overall_count, total_intervals, f"{overall_count_percentage:.2f}%"],
]

base_name = os.path.basename(csv_file_path).rsplit('.', 1)[0]
output_folder_path = f"results"
os.makedirs(output_folder_path, exist_ok=True)
new_filename = os.path.join(output_folder_path, f"{base_name}_results.csv")

with open(new_filename, 'w', newline='') as csvfile:
    csvwriter = csv.writer(csvfile)
    csvwriter.writerow(data[0])
    csvwriter.writerows(data[1:])
